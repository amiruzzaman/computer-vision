{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Light and Shading in Computer Vision\n",
    "\n",
    "**Due Date:** [Insert Due Date]\n",
    "\n",
    "**Name:** [Your Name]\n",
    "\n",
    "**Student ID:** [Your ID]\n",
    "\n",
    "**Course:** [Course Name]\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completing this assignment, you should be able to:\n",
    "1. Understand and implement basic radiometric concepts\n",
    "2. Model Lambertian reflectance and simulate surface shading\n",
    "3. Implement photometric stereo to recover surface normals and albedo\n",
    "4. Reconstruct 3D surfaces from shading information\n",
    "5. Estimate light source direction from images\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. Complete all code cells marked with `# TODO`\n",
    "2. Answer all questions in markdown cells\n",
    "3. Submit both the completed notebook and a PDF export\n",
    "4. Make sure your code is well-documented and includes comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage, signal\n",
    "from scipy.sparse import lil_matrix\n",
    "from scipy.sparse.linalg import lsqr\n",
    "import cv2\n",
    "import imageio\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from skimage import io, color, exposure\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display images\n",
    "def display_image(img, title=\"\", cmap='gray', figsize=(8, 6)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Radiometric Concepts\n",
    "\n",
    "### Exercise 2.1: Understanding the Radiometric Relation\n",
    "\n",
    "Recall the fundamental radiometric relation from Slide 5:\n",
    "\n",
    "$$ E = \\left[ \\frac{\\pi}{4} \\left( \\frac{d}{f} \\right)^2 \\cos^4 \\alpha \\right] L $$\n",
    "\n",
    "Where:\n",
    "- $E$ = Image irradiance\n",
    "- $L$ = Scene radiance\n",
    "- $d$ = Lens diameter\n",
    "- $f$ = Focal length\n",
    "- $\\alpha$ = Angle between viewing ray and optical axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_irradiance(L, d, f, alpha):\n",
    "    \"\"\"\n",
    "    Compute image irradiance from scene radiance using the fundamental radiometric relation.\n",
    "    \n",
    "    Parameters:\n",
    "    L: Scene radiance (W/(m²·sr))\n",
    "    d: Lens diameter (mm)\n",
    "    f: Focal length (mm)\n",
    "    alpha: Angle from optical axis (radians)\n",
    "    \n",
    "    Returns:\n",
    "    E: Image irradiance (W/m²)\n",
    "    \"\"\"\n",
    "    # TODO: Implement the radiometric relation\n",
    "    # Convert d and f to meters if needed\n",
    "    d_m = d / 1000.0  # mm to m\n",
    "    f_m = f / 1000.0  # mm to m\n",
    "    \n",
    "    # Compute the term in brackets\n",
    "    bracket_term = (np.pi / 4) * ((d_m / f_m) ** 2) * (np.cos(alpha) ** 4)\n",
    "    \n",
    "    # Compute irradiance\n",
    "    E = bracket_term * L\n",
    "    \n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "L_test = 100  # W/(m²·sr)\n",
    "d_test = 50   # mm\n",
    "f_test = 35   # mm\n",
    "\n",
    "# Test at different angles\n",
    "angles = np.linspace(0, np.pi/3, 10)\n",
    "irradiances = [compute_irradiance(L_test, d_test, f_test, a) for a in angles]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.degrees(angles), irradiances, 'bo-', linewidth=2)\n",
    "plt.xlabel('Angle α (degrees)')\n",
    "plt.ylabel('Irradiance E (W/m²)')\n",
    "plt.title('Irradiance vs. Viewing Angle (cos⁴ law)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1:**\n",
    "\n",
    "1. What happens to the irradiance as α increases from 0 to 60 degrees?\n",
    "2. Why does the irradiance drop so rapidly with increasing angle?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "[Write your answer here]\n",
    "\n",
    "1. As α increases from 0 to 60 degrees, the irradiance decreases according to the cos⁴(α) term. At α=60°, cos(60°)=0.5, so cos⁴(60°)=0.0625, meaning the irradiance is only about 6.25% of what it is at the center (α=0).\n",
    "\n",
    "2. The rapid drop (cos⁴ law) occurs due to multiple factors:\n",
    "   - Geometric foreshortening (cos α)\n",
    "   - Increased distance from lens center (cos α)\n",
    "   - Oblique incidence on sensor (cos α)\n",
    "   - Lens vignetting effects\n",
    "   These factors combine to give the fourth-power relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Lambertian Reflectance and Shading\n",
    "\n",
    "### Exercise 3.1: Implementing Lambert's Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambertian_shading(normals, light_direction, albedo=1.0):\n",
    "    \"\"\"\n",
    "    Compute Lambertian shading for a surface.\n",
    "    \n",
    "    Parameters:\n",
    "    normals: Array of shape (H, W, 3) containing surface normals\n",
    "    light_direction: 3D vector pointing toward light source (normalized)\n",
    "    albedo: Scalar or array of same spatial dimensions as normals\n",
    "    \n",
    "    Returns:\n",
    "    shading: Array of shape (H, W) with Lambertian intensities\n",
    "    \"\"\"\n",
    "    # TODO: Implement Lambert's law: I = ρ * max(0, N·S)\n",
    "    # Ensure light_direction is normalized\n",
    "    light_direction = light_direction / np.linalg.norm(light_direction)\n",
    "    \n",
    "    # Compute dot product between normals and light direction\n",
    "    dot_product = np.sum(normals * light_direction, axis=-1)\n",
    "    \n",
    "    # Apply max(0, dot_product) to avoid negative values (back-facing surfaces)\n",
    "    shading = albedo * np.maximum(0, dot_product)\n",
    "    \n",
    "    return shading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple spherical surface\n",
    "height, width = 256, 256\n",
    "y, x = np.mgrid[-height//2:height//2, -width//2:width//2]\n",
    "\n",
    "# Create a hemisphere\n",
    "radius = height // 2\n",
    "mask = x**2 + y**2 <= radius**2\n",
    "\n",
    "# Create z coordinates (height) for a hemisphere\n",
    "z = np.zeros_like(x, dtype=float)\n",
    "z[mask] = np.sqrt(np.maximum(0, radius**2 - x[mask]**2 - y[mask]**2))\n",
    "\n",
    "# Compute surface normals\n",
    "def compute_normals(z):\n",
    "    \"\"\"Compute surface normals from height map.\"\"\"\n",
    "    # Compute gradients\n",
    "    dz_dx = np.gradient(z, axis=1)\n",
    "    dz_dy = np.gradient(z, axis=0)\n",
    "    \n",
    "    # Normals are [-dz/dx, -dz/dy, 1]\n",
    "    normals = np.stack([-dz_dx, -dz_dy, np.ones_like(z)], axis=-1)\n",
    "    \n",
    "    # Normalize\n",
    "    norms = np.linalg.norm(normals, axis=-1, keepdims=True)\n",
    "    norms[norms == 0] = 1  # Avoid division by zero\n",
    "    normals = normals / norms\n",
    "    \n",
    "    return normals\n",
    "\n",
    "normals = compute_normals(z)\n",
    "\n",
    "# Test Lambertian shading with different light directions\n",
    "light_directions = [\n",
    "    np.array([0, 0, 1]),      # From above\n",
    "    np.array([1, 0, 1]),      # From top-right\n",
    "    np.array([-1, -1, 1]),    # From bottom-left\n",
    "    np.array([0, -1, 0.5]),   # From bottom\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, light_dir in enumerate(light_directions):\n",
    "    shading = lambertian_shading(normals, light_dir)\n",
    "    \n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(shading, cmap='gray')\n",
    "    plt.title(f'Light direction: {light_dir}')\n",
    "    plt.axis('off')\n",
    "    plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:**\n",
    "\n",
    "1. What happens when the dot product N·S becomes negative? Why do we take max(0, N·S)?\n",
    "2. How would you modify the function to simulate attached shadows vs. cast shadows?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "[Write your answer here]\n",
    "\n",
    "1. When N·S becomes negative, it means the surface is facing away from the light source (back-facing). We take max(0, N·S) because physically, surfaces facing away from the light shouldn't receive direct illumination (though they might receive indirect light via global illumination).\n",
    "\n",
    "2. To simulate cast shadows, we would need to implement ray tracing or shadow mapping to check if the point is visible from the light source. For attached shadows (self-shading), our current max(0, N·S) already handles it. For cast shadows, we'd need to trace rays from each point to the light source and check for occlusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Photometric Stereo\n",
    "\n",
    "### Exercise 4.1: Implementing Basic Photometric Stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photometric_stereo(images, light_directions, mask=None):\n",
    "    \"\"\"\n",
    "    Perform photometric stereo to recover surface normals and albedo.\n",
    "    \n",
    "    Parameters:\n",
    "    images: List of images (same size) under different lighting\n",
    "    light_directions: List of 3D light direction vectors\n",
    "    mask: Optional binary mask for valid pixels\n",
    "    \n",
    "    Returns:\n",
    "    albedo: Recovered albedo map\n",
    "    normals: Recovered surface normals (H, W, 3)\n",
    "    \"\"\"\n",
    "    # TODO: Implement photometric stereo\n",
    "    # Convert inputs to numpy arrays\n",
    "    images = np.array(images)  # Shape: (n_images, H, W)\n",
    "    light_directions = np.array(light_directions)  # Shape: (n_images, 3)\n",
    "    \n",
    "    # Get dimensions\n",
    "    n_images, H, W = images.shape\n",
    "    \n",
    "    # Reshape images to (n_images, n_pixels)\n",
    "    n_pixels = H * W\n",
    "    I = images.reshape(n_images, n_pixels)\n",
    "    \n",
    "    # Light directions matrix V (n_images × 3)\n",
    "    V = light_directions\n",
    "    \n",
    "    # Solve g = ρN for each pixel: V g = I\n",
    "    # We'll solve using least squares for each pixel\n",
    "    g = np.zeros((3, n_pixels))\n",
    "    \n",
    "    for i in range(n_pixels):\n",
    "        # Solve for g at pixel i: V g_i = I_i\n",
    "        g_i, _, _, _ = np.linalg.lstsq(V, I[:, i], rcond=None)\n",
    "        g[:, i] = g_i\n",
    "    \n",
    "    # Reshape g to spatial dimensions\n",
    "    g = g.reshape(3, H, W)\n",
    "    g = np.transpose(g, (1, 2, 0))  # Shape: (H, W, 3)\n",
    "    \n",
    "    # Compute albedo as magnitude of g\n",
    "    albedo = np.linalg.norm(g, axis=-1)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    albedo[albedo == 0] = 1e-10\n",
    "    \n",
    "    # Compute normals: N = g / ρ\n",
    "    normals = g / albedo[..., np.newaxis]\n",
    "    \n",
    "    # Apply mask if provided\n",
    "    if mask is not None:\n",
    "        albedo = albedo * mask\n",
    "        normals = normals * mask[..., np.newaxis]\n",
    "        # Renormalize normals\n",
    "        norms = np.linalg.norm(normals, axis=-1, keepdims=True)\n",
    "        norms[norms == 0] = 1\n",
    "        normals = normals / norms\n",
    "    \n",
    "    return albedo, normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data for testing\n",
    "def generate_synthetic_bump(H=128, W=128):\n",
    "    \"\"\"Generate a synthetic bump surface.\"\"\"\n",
    "    y, x = np.mgrid[:H, :W]\n",
    "    \n",
    "    # Create a bumpy surface using sum of Gaussians\n",
    "    centers = [(W//4, H//4), (3*W//4, H//4), \n",
    "               (W//2, H//2), (W//4, 3*H//4), (3*W//4, 3*H//4)]\n",
    "    z = np.zeros((H, W))\n",
    "    \n",
    "    for cx, cy in centers:\n",
    "        r2 = (x - cx)**2 + (y - cy)**2\n",
    "        z += np.exp(-r2 / (0.05 * min(H, W)**2))\n",
    "    \n",
    "    return z\n",
    "\n",
    "# Generate surface\n",
    "H, W = 128, 128\n",
    "z_true = generate_synthetic_bump(H, W)\n",
    "\n",
    "# Compute true normals\n",
    "normals_true = compute_normals(z_true)\n",
    "\n",
    "# Generate synthetic albedo (varying across surface)\n",
    "albedo_true = 0.5 + 0.3 * np.sin(0.05 * np.mgrid[:H, :W][0]) * np.cos(0.03 * np.mgrid[:H, :W][1])\n",
    "\n",
    "# Generate synthetic images under different lighting\n",
    "n_images = 6\n",
    "light_directions = []\n",
    "images = []\n",
    "\n",
    "for i in range(n_images):\n",
    "    # Generate random light direction\n",
    "    theta = 2 * np.pi * i / n_images\n",
    "    phi = np.pi / 4  # 45 degrees elevation\n",
    "    light_dir = np.array([\n",
    "        np.sin(phi) * np.cos(theta),\n",
    "        np.sin(phi) * np.sin(theta),\n",
    "        np.cos(phi)\n",
    "    ])\n",
    "    light_directions.append(light_dir)\n",
    "    \n",
    "    # Generate image using Lambertian model\n",
    "    I = lambertian_shading(normals_true, light_dir, albedo_true)\n",
    "    \n",
    "    # Add some noise\n",
    "    I += 0.01 * np.random.randn(H, W)\n",
    "    \n",
    "    images.append(I)\n",
    "\n",
    "# Run photometric stereo\n",
    "albedo_est, normals_est = photometric_stereo(images, light_directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Show input images\n",
    "for i in range(min(4, n_images)):\n",
    "    axes[0, i].imshow(images[i], cmap='gray')\n",
    "    axes[0, i].set_title(f'Input {i+1}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Show ground truth and estimated albedo\n",
    "axes[1, 0].imshow(albedo_true, cmap='gray')\n",
    "axes[1, 0].set_title('True Albedo')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(albedo_est, cmap='gray')\n",
    "axes[1, 1].set_title('Estimated Albedo')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "# Visualize normals as RGB\n",
    "def normals_to_rgb(normals):\n",
    "    \"\"\"Convert normals ([-1,1]) to RGB image ([0,1]).\"\"\"\n",
    "    rgb = (normals + 1) / 2\n",
    "    return np.clip(rgb, 0, 1)\n",
    "\n",
    "axes[1, 2].imshow(normals_to_rgb(normals_true))\n",
    "axes[1, 2].set_title('True Normals')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "axes[1, 3].imshow(normals_to_rgb(normals_est))\n",
    "axes[1, 3].set_title('Estimated Normals')\n",
    "axes[1, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.2: Surface Reconstruction from Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_normals(normals, method='frankot_chellappa'):\n",
    "    \"\"\"\n",
    "    Reconstruct surface height from surface normals.\n",
    "    \n",
    "    Parameters:\n",
    "    normals: Array of shape (H, W, 3) containing surface normals\n",
    "    method: Integration method ('frankot_chellappa' or 'simple')\n",
    "    \n",
    "    Returns:\n",
    "    z: Reconstructed height map\n",
    "    \"\"\"\n",
    "    H, W = normals.shape[:2]\n",
    "    \n",
    "    # Extract surface gradients from normals\n",
    "    # N = [-p, -q, 1] / sqrt(p² + q² + 1)\n",
    "    # So p = -Nx/Nz, q = -Ny/Nz\n",
    "    Nx, Ny, Nz = normals[..., 0], normals[..., 1], normals[..., 2]\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    Nz[Nz == 0] = 1e-10\n",
    "    \n",
    "    p = -Nx / Nz  # ∂z/∂x\n",
    "    q = -Ny / Nz  # ∂z/∂y\n",
    "    \n",
    "    if method == 'simple':\n",
    "        # Simple integration by cumulative sum\n",
    "        z = np.zeros((H, W))\n",
    "        \n",
    "        # Integrate along rows\n",
    "        for i in range(H):\n",
    "            z[i, 1:] = np.cumsum(p[i, :]) * (1.0 / W)\n",
    "        \n",
    "        # Integrate along columns\n",
    "        for j in range(W):\n",
    "            z[:, j] += np.cumsum(q[:, j]) * (1.0 / H)\n",
    "            \n",
    "        # Average\n",
    "        z = z / 2\n",
    "        \n",
    "    elif method == 'frankot_chellappa':\n",
    "        # Frankot-Chellappa algorithm in Fourier domain\n",
    "        # TODO: Implement Frankot-Chellappa algorithm\n",
    "        # Create frequency grids\n",
    "        u = np.fft.fftfreq(W) * 2 * np.pi\n",
    "        v = np.fft.fftfreq(H) * 2 * np.pi\n",
    "        U, V = np.meshgrid(u, v)\n",
    "        \n",
    "        # Avoid division by zero at DC\n",
    "        denom = U**2 + V**2\n",
    "        denom[0, 0] = 1  # Avoid division by zero\n",
    "        \n",
    "        # Compute Fourier transforms of gradients\n",
    "        P_hat = np.fft.fft2(p)\n",
    "        Q_hat = np.fft.fft2(q)\n",
    "        \n",
    "        # Compute Fourier transform of height\n",
    "        Z_hat = (-1j * U * P_hat - 1j * V * Q_hat) / denom\n",
    "        \n",
    "        # Set DC component to 0 (arbitrary base height)\n",
    "        Z_hat[0, 0] = 0\n",
    "        \n",
    "        # Inverse Fourier transform\n",
    "        z = np.real(np.fft.ifft2(Z_hat))\n",
    "    \n",
    "    # Remove mean\n",
    "    z = z - np.mean(z)\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test surface reconstruction\n",
    "z_reconstructed = integrate_normals(normals_est, method='frankot_chellappa')\n",
    "\n",
    "# Create 3D visualization\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# True surface\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "Y, X = np.mgrid[:H, :W]\n",
    "surf1 = ax1.plot_surface(X, Y, z_true, cmap=cm.coolwarm, \n",
    "                        linewidth=0, antialiased=True, alpha=0.8)\n",
    "ax1.set_title('True Surface')\n",
    "ax1.set_zlim(z_true.min(), z_true.max())\n",
    "\n",
    "# Reconstructed surface\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "surf2 = ax2.plot_surface(X, Y, z_reconstructed, cmap=cm.coolwarm,\n",
    "                        linewidth=0, antialiased=True, alpha=0.8)\n",
    "ax2.set_title('Reconstructed Surface')\n",
    "ax2.set_zlim(z_reconstructed.min(), z_reconstructed.max())\n",
    "\n",
    "# Error map\n",
    "ax3 = fig.add_subplot(133)\n",
    "error = np.abs(z_reconstructed - z_true)\n",
    "im = ax3.imshow(error, cmap='hot')\n",
    "ax3.set_title('Reconstruction Error')\n",
    "plt.colorbar(im, ax=ax3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute reconstruction error\n",
    "mse = np.mean((z_reconstructed - z_true)**2)\n",
    "print(f\"Mean Squared Error: {mse:.6f}\")\n",
    "print(f\"Average Error: {np.mean(np.abs(z_reconstructed - z_true)):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1:**\n",
    "\n",
    "1. What are the limitations of the simple integration method compared to Frankot-Chellappa?\n",
    "2. Why might the reconstructed surface differ from the ground truth even with perfect normals?\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "[Write your answer here]\n",
    "\n",
    "1. The simple integration method is path-dependent and accumulates errors along the integration path. It doesn't enforce integrability constraints (∂²z/∂x∂y = ∂²z/∂y∂x). Frankot-Chellappa works in the frequency domain and finds the surface that best fits the gradients in a least-squares sense, enforcing integrability globally.\n",
    "\n",
    "2. Even with perfect normals, the reconstruction can differ due to:\n",
    "   - The arbitrary constant of integration (unknown absolute height)\n",
    "   - The periodic boundary assumption in Fourier methods\n",
    "   - Missing low-frequency information (DC component)\n",
    "   - Numerical errors in integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Light Source Direction Estimation\n",
    "\n",
    "### Exercise 5.1: Estimating Light Direction from Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_light_direction(images, normals, mask=None):\n",
    "    \"\"\"\n",
    "    Estimate light direction from images and known normals.\n",
    "    \n",
    "    Parameters:\n",
    "    images: List of images under the same light\n",
    "    normals: Known surface normals\n",
    "    mask: Optional mask for valid pixels\n",
    "    \n",
    "    Returns:\n",
    "    light_direction: Estimated 3D light direction\n",
    "    \"\"\"\n",
    "    # TODO: Implement light direction estimation\n",
    "    # For multiple images, we could average or use RANSAC\n",
    "    # For simplicity, we'll use the first image\n",
    "    \n",
    "    if isinstance(images, list):\n",
    "        I = images[0]\n",
    "    else:\n",
    "        I = images\n",
    "    \n",
    "    H, W = I.shape[:2]\n",
    "    \n",
    "    # Flatten arrays\n",
    "    I_flat = I.flatten()\n",
    "    N_flat = normals.reshape(-1, 3)\n",
    "    \n",
    "    # Apply mask if provided\n",
    "    if mask is not None:\n",
    "        mask_flat = mask.flatten()\n",
    "        I_flat = I_flat[mask_flat > 0]\n",
    "        N_flat = N_flat[mask_flat > 0]\n",
    "    \n",
    "    # Solve for S in I = ρ * (N·S)\n",
    "    # We'll assume constant albedo ρ = 1 for now\n",
    "    # Solve using least squares: N S = I\n",
    "    \n",
    "    # Add small regularization\n",
    "    N_T = N_flat.T\n",
    "    A = N_flat.T @ N_flat + 1e-6 * np.eye(3)\n",
    "    b = N_flat.T @ I_flat\n",
    "    \n",
    "    S = np.linalg.solve(A, b)\n",
    "    \n",
    "    # Normalize\n",
    "    S = S / np.linalg.norm(S)\n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test light direction estimation\n",
    "# Use our synthetic data from earlier\n",
    "# We'll use one of our generated images and the true normals\n",
    "\n",
    "test_image_idx = 0\n",
    "I_test = images[test_image_idx]\n",
    "true_light_dir = light_directions[test_image_idx]\n",
    "\n",
    "# Estimate light direction\n",
    "estimated_light_dir = estimate_light_direction(I_test, normals_true)\n",
    "\n",
    "print(f\"True light direction: {true_light_dir}\")\n",
    "print(f\"Estimated light direction: {estimated_light_dir}\")\n",
    "print(f\"Angular error: {np.degrees(np.arccos(np.clip(np.dot(true_light_dir, estimated_light_dir), -1, 1))):.2f}°\")\n",
    "\n",
    "# Visualize\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.imshow(I_test, cmap='gray')\n",
    "ax1.set_title('Input Image')\n",
    "ax1.axis('off')\n",
    "\n",
    "# Create a simple visualization of light directions\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "# Plot unit sphere\n",
    "u = np.linspace(0, 2 * np.pi, 100)\n",
    "v = np.linspace(0, np.pi, 100)\n",
    "x = np.outer(np.cos(u), np.sin(v))\n",
    "y = np.outer(np.sin(u), np.sin(v))\n",
    "z = np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "ax2.plot_surface(x, y, z, color='gray', alpha=0.1)\n",
    "\n",
    "# Plot light directions\n",
    "ax2.quiver(0, 0, 0, true_light_dir[0], true_light_dir[1], true_light_dir[2], \n",
    "          color='g', label='True', linewidth=3)\n",
    "ax2.quiver(0, 0, 0, estimated_light_dir[0], estimated_light_dir[1], estimated_light_dir[2],\n",
    "          color='r', label='Estimated', linewidth=3)\n",
    "\n",
    "ax2.set_xlim([-1, 1])\n",
    "ax2.set_ylim([-1, 1])\n",
    "ax2.set_zlim([-1, 1])\n",
    "ax2.set_title('Light Directions')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Advanced Challenge (Optional)\n",
    "\n",
    "### Exercise 6.1: Handling Non-Lambertian Surfaces\n",
    "\n",
    "Real surfaces often exhibit both diffuse and specular reflection. The Phong reflection model combines these:\n",
    "\n",
    "$$ I = I_{\\text{diffuse}} + I_{\\text{specular}} = \\rho_d (\\mathbf{N} \\cdot \\mathbf{L}) + \\rho_s (\\mathbf{R} \\cdot \\mathbf{V})^n $$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{R}$ is the reflection vector\n",
    "- $\\mathbf{V}$ is the view direction\n",
    "- $n$ is the shininess coefficient\n",
    "- $\\rho_d$ and $\\rho_s$ are diffuse and specular albedos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phong_shading(normals, light_direction, view_direction, \n",
    "                  diffuse_albedo=1.0, specular_albedo=0.5, shininess=50):\n",
    "    \"\"\"\n",
    "    Implement Phong shading model.\n",
    "    \n",
    "    Parameters:\n",
    "    normals: Surface normals\n",
    "    light_direction: Light direction vector\n",
    "    view_direction: View/camera direction vector\n",
    "    diffuse_albedo: Diffuse reflectance\n",
    "    specular_albedo: Specular reflectance\n",
    "    shininess: Specular exponent\n",
    "    \n",
    "    Returns:\n",
    "    I: Shaded image\n",
    "    \"\"\"\n",
    "    # TODO: Implement Phong shading model\n",
    "    # Normalize directions\n",
    "    light_direction = light_direction / np.linalg.norm(light_direction)\n",
    "    view_direction = view_direction / np.linalg.norm(view_direction)\n",
    "    \n",
    "    # Diffuse component\n",
    "    diffuse = diffuse_albedo * np.maximum(0, np.sum(normals * light_direction, axis=-1))\n",
    "    \n",
    "    # Compute reflection vector: R = 2*(N·L)*N - L\n",
    "    N_dot_L = np.sum(normals * light_direction, axis=-1, keepdims=True)\n",
    "    reflection = 2 * N_dot_L * normals - light_direction\n",
    "    \n",
    "    # Normalize reflection vectors\n",
    "    ref_norm = np.linalg.norm(reflection, axis=-1, keepdims=True)\n",
    "    ref_norm[ref_norm == 0] = 1\n",
    "    reflection = reflection / ref_norm\n",
    "    \n",
    "    # Specular component\n",
    "    R_dot_V = np.sum(reflection * view_direction, axis=-1)\n",
    "    specular = specular_albedo * np.maximum(0, R_dot_V) ** shininess\n",
    "    \n",
    "    # Total shading\n",
    "    I = diffuse + specular\n",
    "    \n",
    "    return I, diffuse, specular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Phong shading\n",
    "test_normals = normals_true\n",
    "test_light_dir = np.array([1, 1, 1]) / np.sqrt(3)\n",
    "test_view_dir = np.array([0, 0, 1])\n",
    "\n",
    "I_phong, diffuse, specular = phong_shading(\n",
    "    test_normals, test_light_dir, test_view_dir,\n",
    "    diffuse_albedo=0.7, specular_albedo=0.3, shininess=100\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "titles = ['Phong Shading', 'Diffuse Component', 'Specular Component', 'Normals (RGB)']\n",
    "images = [I_phong, diffuse, specular, normals_to_rgb(test_normals)]\n",
    "\n",
    "for ax, img, title in zip(axes, images, titles):\n",
    "    if title == 'Normals (RGB)':\n",
    "        ax.imshow(img)\n",
    "    else:\n",
    "        ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Real-world Application\n",
    "\n",
    "### Exercise 7.1: Loading and Processing Real Images\n",
    "\n",
    "For this exercise, we'll work with a sample dataset (you can replace with your own images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample images (you'll need to replace these with actual image files)\n",
    "# This is a template - in practice, you would load real images\n",
    "\n",
    "def load_sample_images():\n",
    "    \"\"\"\n",
    "    Template function for loading real images.\n",
    "    In practice, you would load images from files.\n",
    "    \"\"\"\n",
    "    print(\"Template function - replace with actual image loading code\")\n",
    "    \n",
    "    # Example of what you might do:\n",
    "    # image_paths = ['image1.jpg', 'image2.jpg', 'image3.jpg']\n",
    "    # images = [io.imread(path) for path in image_paths]\n",
    "    # light_directions = [...]  # You would need to know or estimate these\n",
    "    \n",
    "    # For now, return synthetic data\n",
    "    return images, light_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for real image processing\n",
    "try:\n",
    "    # Uncomment and modify this when you have real images\n",
    "    # real_images, real_light_dirs = load_sample_images()\n",
    "    \n",
    "    # If you have real images, you can run photometric stereo on them:\n",
    "    # albedo_real, normals_real = photometric_stereo(real_images, real_light_dirs)\n",
    "    # z_real = integrate_normals(normals_real)\n",
    "    \n",
    "    print(\"Real image processing code would go here.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading images: {e}\")\n",
    "    print(\"Continuing with synthetic examples...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Discussion Questions\n",
    "\n",
    "**Answer the following questions in this markdown cell:**\n",
    "\n",
    "1. **What are the main challenges in applying photometric stereo to real-world images?**\n",
    "\n",
    "   [Your answer here]\n",
    "\n",
    "   Real-world challenges include:\n",
    "   - Non-Lambertian surfaces (specularities, interreflections)\n",
    "   - Unknown or inaccurate light source directions\n",
    "   - Camera nonlinearities (response function)\n",
    "   - Shadows and occlusions\n",
    "   - Surface texture interfering with albedo estimation\n",
    "   - Need for precise camera calibration\n",
    "\n",
    "2. **How does shape from shading differ from photometric stereo? What are the advantages and disadvantages of each?**\n",
    "\n",
    "   [Your answer here]\n",
    "\n",
    "   Shape from shading (SfS) uses a single image but requires strong assumptions about lighting and reflectance. Photometric stereo uses multiple images under different lighting but requires known light directions.\n",
    "   \n",
    "   SfS advantages: single image, simpler setup.\n",
    "   SfS disadvantages: ambiguous, requires strong priors, sensitive to assumptions.\n",
    "   \n",
    "   Photometric stereo advantages: more robust, can separate albedo and shape.\n",
    "   Photometric stereo disadvantages: requires controlled lighting, multiple images, known light directions.\n",
    "\n",
    "3. **How might modern deep learning approaches improve upon classical shape from shading methods?**\n",
    "\n",
    "   [Your answer here]\n",
    "\n",
    "   Deep learning can:\n",
    "   - Learn complex reflectance models from data\n",
    "   - Handle non-Lambertian surfaces\n",
    "   - Work with single images without known lighting\n",
    "   - Incorporate semantic understanding of objects\n",
    "   - Handle shadows and interreflections better\n",
    "   - Learn from large datasets of real-world examples\n",
    "\n",
    "4. **What applications can benefit from accurate shape from shading or photometric stereo?**\n",
    "\n",
    "   [Your answer here]\n",
    "\n",
    "   Applications include:\n",
    "   - 3D reconstruction from images\n",
    "   - Digital heritage preservation\n",
    "   - Industrial inspection (surface defect detection)\n",
    "   - Medical imaging (skin lesion analysis)\n",
    "   - Autonomous driving (road surface analysis)\n",
    "   - Augmented reality (realistic object insertion)\n",
    "   - Forensic analysis (detecting image forgeries)\n",
    "\n",
    "---\n",
    "\n",
    "## Submission Instructions\n",
    "\n",
    "1. Complete all TODOs in the code cells\n",
    "2. Answer all discussion questions\n",
    "3. Run the entire notebook to ensure it works\n",
    "4. Export to PDF (File → Download as → PDF via LaTeX)\n",
    "5. Submit both the .ipynb and .pdf files\n",
    "\n",
    "**Grading Rubric:**\n",
    "- Code correctness and completeness: 60%\n",
    "- Discussion questions: 30%\n",
    "- Code comments and documentation: 10%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}